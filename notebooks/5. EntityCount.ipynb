{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kU5liNrKrptN"
   },
   "source": [
    "# Entity Count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Iayuf1P7orQf"
   },
   "source": [
    " CaseOLAP score calculation requires the entity count per document. This step provides the data which connects metadata for text-cube structure and entity-count per document.\n",
    " \n",
    "**Selection of entity** : Entity(phrase) are defined by user to be studied under the text-cube document structure. User defined entity could be protein names, chemicals, disease or signs and symptoms etc.\n",
    "Search and listing of entity based document: The search functionality in  Elasticsearch DSL package uses index name, parameters and query to list the document from indexed database. The query includes all representatives of the specific entity e.g. synonyms, abbreviations. \n",
    "\n",
    "**Entity count** : Then each document from the list is analysed one by one to count the entity also called term frequency, ```tf(p,c)``` . With the help of text-cube metadata, for each of the document in cell of the text-cube, the entity count is recorded as PMID to entity count mapping.\n",
    "\n",
    "**Text-cube metadata update** : Once the entity count is completed, text cube metadata is updated by adding PMID to entity count mapping . Following are the additional metadata prepared:\n",
    "- count the total occurance of each entity ```cntP(c)```  within each cell,\n",
    "- count the total number of documents ```df(p,c)``` within a cell in which entity appears.\n",
    "- calculate normalized term frequency  ```ntf(p,c)``` [eq ref]  and normalized document frequency  ndf(p,c) [eq ref] using quantities obtained from 5.4.1 and 5.4.2\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WmKE8vW-rptO"
   },
   "source": [
    "#### Import required libearies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "Mifiae0frptP"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import json\n",
    "from elasticsearch import Elasticsearch\n",
    "from elasticsearch_dsl import Search, Q\n",
    "from collections import Counter\n",
    "\n",
    "year_constraints = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KiJhNTsfrptU"
   },
   "source": [
    "#### Setting up input output directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "P9UGHGd7rptW"
   },
   "outputs": [],
   "source": [
    "input_index_dir = \"../../elasticsearch-6.2.2/data\"\n",
    "#input_index_dir = \"data/index_full_pubmed\"\n",
    "input_file_pmid_and_cat = \"input/CVD_pmid_and_cat.json\"\n",
    "input_file_entity_list = \"../data/CVD_proteins_8325_new_BNP.txt\"\n",
    "\n",
    "output_file_paper_entity_count = \"output/CVD_paper_entity_count.txt\"\n",
    "output_file_paper_category = \"output/CVD_paper_category.txt\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4j9buqn0rpta"
   },
   "source": [
    "#### Read in paper info and entity info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "AJsvAtpZrptb"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Read in paper info and entity info\n",
    "\"\"\"\n",
    "with open(input_file_pmid_and_cat, \"r\") as f_in:\n",
    "    pmid_and_cat = json.load(f_in)\n",
    "concerned_pmid_set = set(map(lambda x: x[0], pmid_and_cat))\n",
    "\n",
    "entity_count_per_pmid = {pmid: Counter() for pmid in concerned_pmid_set}\n",
    "\n",
    "\n",
    "entity_dict = {}\n",
    "with open(input_file_entity_list, \"r\") as f_in:\n",
    "    for line in f_in:\n",
    "        # synonums seperated by \"|\" and represented by the first one on each line\n",
    "        line_split = line.strip().split(\"|\")\n",
    "        entity_dict[line_split[0]] = line_split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SRct8NZgrptf"
   },
   "source": [
    "#### Search and count entities: to optimize and find count from indexer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "T4bC0zOmrptf"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Search and count entities: to optimize and find count from indexer\n",
    "\"\"\"\n",
    "es = Elasticsearch(timeout=300)\n",
    "k = 0\n",
    "for entity_rep in entity_dict:\n",
    "    for entity in entity_dict[entity_rep]:\n",
    "        \n",
    "        \n",
    "        #entity_space_sep = \"\".join(map(lambda x: \" \" if x == \"_\" else x, entity))\n",
    "        entity_space_sep = entity.replace(\"_\", \" \")\n",
    "        \n",
    "        \n",
    "        \n",
    "        # s = Search(using=es, index=\"pmc_all_index\").query(\"match\", abstract=entity_space_sep)\n",
    "        s = Search(using=es, index=\"pubmed\")\\\n",
    "                    .params(request_timeout=300)\\\n",
    "                    .query(\"match_phrase\", abstract=entity_space_sep)\n",
    "                \n",
    "\n",
    "        num_hits = 0\n",
    "        num_valid_hits = 0\n",
    "        num_counts = 0\n",
    "        \n",
    "        for hit in s.scan():\n",
    "            num_hits += 1\n",
    "            cur_pmid = str(hit.pmid)\n",
    "            if cur_pmid not in concerned_pmid_set:\n",
    "                continue\n",
    "                \n",
    "            #if hit.PMCflag != 0:\n",
    "            #    continue\n",
    "            if year_constraints is not None:\n",
    "                # to-do\n",
    "                print(\"To add year constraint handler.\")\n",
    "\n",
    "                \n",
    "            abs_lower = hit.abstract.lower().replace(\"-\", \" \")\n",
    "            entity_lower = entity_space_sep.lower().replace(\"-\", \" \")\n",
    "            entity_cnt = abs_lower.count(entity_lower)\n",
    "\n",
    "            \n",
    "            if entity_cnt == 0:\n",
    "                #print \"----------\", entity_space_sep, \"----------\"\n",
    "                #print abs_lower\n",
    "                continue\n",
    "\n",
    "                \n",
    "            entity_count_per_pmid[cur_pmid][entity_rep] += entity_cnt\n",
    "            num_valid_hits += 1\n",
    "            num_counts += entity_cnt\n",
    "\n",
    "        #print(entity, \"# hits:\", num_hits, \"# valid hits:\", num_valid_hits, \"# counts:\", num_counts)\n",
    "    k = k +1\n",
    "    if k%1000 == 0:\n",
    "        print(k,'entity counted!')\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eSyjXeNErptl"
   },
   "source": [
    "### Entity count metadata update in each Cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "AD8V2LeRrpto"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Output\n",
    "\"\"\"\n",
    "## paper entity count & paper category\n",
    "with open(output_file_paper_entity_count, \"w\") as f_out_entity_count,\\\n",
    "        open(output_file_paper_category, \"w\") as f_out_category:\n",
    "    f_out_category.write(\"doc_id\\tlabel_id\\n\")\n",
    "    \n",
    "    paper_new_id = 1\n",
    "    \n",
    "    for cur_pmid, cur_cat in pmid_and_cat:\n",
    "        \n",
    "        if len(entity_count_per_pmid[cur_pmid]) == 0:\n",
    "            continue\n",
    "            \n",
    "            \n",
    "        # print paper category\n",
    "        f_out_category.write(str(cur_pmid) + \"\\t\" + str(cur_cat) + \"\\n\")\n",
    "        \n",
    "        \n",
    "        # print paper entity count\n",
    "        f_out_entity_count.write(str(cur_pmid))\n",
    "        \n",
    "        \n",
    "        for entity in entity_count_per_pmid[cur_pmid]:\n",
    "            f_out_entity_count.write(\" \" + entity +\"|\" + str(entity_count_per_pmid[cur_pmid][entity]))\n",
    "            \n",
    "            \n",
    "        f_out_entity_count.write(\"\\n\")\n",
    "\n",
    "        \n",
    "        paper_new_id += 1\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "default_view": {},
   "name": "5. EntityCount.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
